{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кластеризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "def get_models(data, name='Data'):\n",
    "    models = []\n",
    "    inertia = []\n",
    "    silhouette = []\n",
    "    print(name, end=': ')\n",
    "    for n_clusters in range(2, 16):\n",
    "        print(n_clusters, end=', ')\n",
    "        # Описываем модель\n",
    "        model = KMeans(n_clusters=n_clusters, max_iter=5000, random_state=0)\n",
    "\n",
    "        # Проводим моделирование\n",
    "        model.fit(data)\n",
    "\n",
    "        # Предсказание на всем наборе данных\n",
    "        all_predictions = model.predict(data)\n",
    "\n",
    "        # Распихиваем точки по кластерам\n",
    "        clusters = [[] for i in range(n_clusters)]\n",
    "        for i, num in enumerate(all_predictions):\n",
    "            clusters[num] += [data[i]]\n",
    "        \n",
    "        models += [model]\n",
    "        inertia += [model.inertia_]\n",
    "        silhouette += [silhouette_score(data, model.labels_, metric='euclidean')]\n",
    "    print('done!')\n",
    "    return models, inertia, silhouette"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут формируем массивы обучабщих выборок для обоих методов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotient_deviation_df_A = pd.read_excel('../output/quotient_deviation_df_A.xlsx')\n",
    "quotient_deviation_df_B = pd.read_excel('../output/quotient_deviation_df_B.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quo_data_A  = np.array(quotient_deviation_df_A.drop(['Year'], axis=1))\n",
    "quo_data_B  = np.array(quotient_deviation_df_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модели для каждого метода:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A quo: 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, done!\n",
      "B quo: 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, done!\n"
     ]
    }
   ],
   "source": [
    "models_quo_A, i_1, s_1 = get_models(quo_data_A, 'A quo')\n",
    "models_quo_B, i_1, s_1 = get_models(quo_data_B, 'B quo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция сохранения графиков кластеров и их средних объектов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_clusters(models, data, amount=15, num=3, data_type='below', ylim=None):\n",
    "    all_predictions = models[num-2].predict(data)\n",
    "    try:\n",
    "        os.mkdir(f'../output/{data_type}/')\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    try:\n",
    "        os.mkdir(f'../output/{data_type}/{num}_clust/')\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    for j in range(num):\n",
    "        fig, ax = plt.subplots( nrows=1, ncols=1)\n",
    "        ax.plot(range(1,amount+1), models[num-2].cluster_centers_[j])\n",
    "        ax.set_title(f'Mean object (cluster №{j+1})')\n",
    "        if ylim:\n",
    "            ax.set_ylim(ylim)\n",
    "        fig.savefig(f'output/{data_type}/{num}_clust/mean_obj_cluster_{j+1}.png')\n",
    "        plt.close(fig)\n",
    "        \n",
    "        fig, ax = plt.subplots( nrows=1, ncols=1)\n",
    "        els = 0\n",
    "        for i in range(len(all_predictions)):\n",
    "            if all_predictions[i] == j:\n",
    "                ax.plot(range(1,amount+1), data[i], label=str(i))\n",
    "                els += 1\n",
    "        #legend(frameon=False)\n",
    "        if ylim:\n",
    "            ax.set_ylim(ylim)\n",
    "        ax.set_title(f'Cluster №{j+1} ({els} elements)')\n",
    "        fig.savefig(f'../output/{data_type}/{num}_clust/cluster_{j+1}.png') \n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_save_clusters(models, data, amount=15, num=3, data_type='below', ylim=None):\n",
    "    all_predictions = models[num-2].predict(data)\n",
    "    try:\n",
    "        os.mkdir(f'../output/final_{data_type}/')\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    try:\n",
    "        os.mkdir(f'../output/final_{data_type}/{num}_clust/')\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    for j in range(num):\n",
    "\n",
    "        fig, ax = plt.subplots( nrows=1, ncols=1, dpi=300)\n",
    "\n",
    "        els = 0\n",
    "        for i in range(len(all_predictions)):\n",
    "            if all_predictions[i] == j:\n",
    "                ax.plot(range(1,amount+1), data[i], label=str(i), color='lightgray')\n",
    "                els += 1\n",
    "\n",
    "        ax.axhline(y=1, color='dimgray', linestyle='--')\n",
    "        ax.axvline(x=15, color='dimgray', linestyle='dotted')\n",
    "\n",
    "        \n",
    "        ax.plot(range(1,amount+1), models[num-2].cluster_centers_[j], color='black')\n",
    "\n",
    "        ax.text(0.15, 0.90, 'Diam',\n",
    "                verticalalignment='bottom', horizontalalignment='right',\n",
    "                transform=ax.transAxes, fontsize=15)\n",
    "        ax.text(0.6, 0.90, 'CWT',\n",
    "                verticalalignment='bottom', horizontalalignment='right',\n",
    "                transform=ax.transAxes, fontsize=15)\n",
    "        \n",
    "        if ylim:\n",
    "            ax.set_ylim(ylim)\n",
    "        ax.set_title(f'Cluster №{j+1} ({els} elements)')\n",
    "        #plt.show()\n",
    "        fig.savefig(f'../output/final_{data_type}/{num}_clust/cluster_{j+1}.png', dpi=300) \n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем графики для всех моделей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3, 6):\n",
    "    save_clusters(models_quo_A, quo_data_A, 30, _, 'A_Quotient', [0.5, 1.5])\n",
    "    save_clusters(models_quo_B, quo_data_B, 30, _, 'B_Quotient', [0.5, 1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(4, 5):\n",
    "    final_save_clusters(models_quo_A, quo_data_A, 30, _, 'A_Quotient', [0.7, 1.3])\n",
    "    #final_save_clusters(models_quo_B, quo_data_B, 30, _, 'B_Quotient', [0.7, 1.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем таблицы кластеризованных объектов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 16):\n",
    "    quotient_deviation_df_A[f'Class {i}'] = models_quo_A[i-2].predict(quo_data_A)\n",
    "    #difference_deviation_df_A[f'Class {i}'] = models_diff_A[i-2].predict(diff_data_A)\n",
    "    quotient_deviation_df_B[f'Class {i}'] = models_quo_B[i-2].predict(quo_data_B)\n",
    "    #difference_deviation_df_B[f'Class {i}'] = models_diff_B[i-3].predict(diff_data_B)\n",
    "\n",
    "quotient_deviation_df_A.to_excel('../output/quotient_deviation_df_A_CLASSIFIED.xlsx', index=False)\n",
    "#difference_deviation_df_A.to_excel('output/difference_deviation_df_A_CLASSIFIED.xlsx', index=False)\n",
    "quotient_deviation_df_B.to_excel('../output/quotient_deviation_df_B_CLASSIFIED.xlsx', index=True)\n",
    "#difference_deviation_df_B.to_excel('output/difference_deviation_df_B_CLASSIFIED.xlsx', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строим таблицу коэффициентов корреляции Спирмена для двух методов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotient_deviation_df_A = pd.read_excel('../output/quotient_deviation_df_A_CLASSIFIED.xlsx')\n",
    "quotient_deviation_df_B = pd.read_excel('../output/quotient_deviation_df_B_CLASSIFIED_FIXED.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QCorr = quotient_deviation_df_A.drop(['Year'], axis=1).corrwith(\n",
    "        quotient_deviation_df_B.drop(['Year'], axis=1).reset_index(drop=True),\n",
    "        method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = []\n",
    "p_values = []\n",
    "for column in quotient_deviation_df_A.columns:\n",
    "    _c, _p = spearmanr(quotient_deviation_df_A[column], quotient_deviation_df_B[column])\n",
    "    corrs += [_c]\n",
    "    p_values += [_p]\n",
    "\n",
    "spearman_corr_df = pd.DataFrame({'Feature':quotient_deviation_df_A.columns, 'Spearman': corrs, 'P-value': p_values})\n",
    "spearman_corr_df.to_excel('../output/spearman_correlation_new.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строим сравнительные графики для двух методов и двух типов отклонений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_names = [\n",
    "    ['D1', 'D2', 'D3'],\n",
    "    ['D4', 'D5', 'D6'],\n",
    "    ['D7', 'D8', 'D9'],\n",
    "    ['D10', 'D11', 'D12'],\n",
    "    ['D13', 'D14', 'D15']\n",
    "]\n",
    "\n",
    "cwt_names = [\n",
    "    ['CWT1', 'CWT2', 'CWT3'],\n",
    "    ['CWT4', 'CWT5', 'CWT6'],\n",
    "    ['CWT7', 'CWT8', 'CWT9'],\n",
    "    ['CWT10', 'CWT11', 'CWT12'],\n",
    "    ['CWT13', 'CWT14', 'CWT15']\n",
    "]\n",
    "\n",
    "def save_corr_plots(df1, df2, names, corr_row, output_name=''):\n",
    "    fig, ax = plt.subplots(5,3, figsize=(15,12), dpi=300)\n",
    "    for i, row in enumerate(names):\n",
    "        for j, el in enumerate(row):\n",
    "            ax[i, j].scatter(df1[el], df2[el])\n",
    "            ax[i, j].text(0.1, 0.8, f\"{el},  r={corr_row[el]:0.4f}\", transform=ax[i, j].transAxes)\n",
    "    fig.savefig(f'output/{output_name}.png', dpi=300) \n",
    "    plt.close(fig)\n",
    "\n",
    "save_corr_plots(quotient_deviation_df_A, quotient_deviation_df_B, d_names, spearman_corr_df['Quotient'], 'Quotient_D_corr')\n",
    "save_corr_plots(quotient_deviation_df_A, quotient_deviation_df_B, cwt_names, spearman_corr_df['Quotient'], 'Quotient_CWT_corr')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ea00faadcfb8ab3c64085c6facc6f20135a21130ce7141e34f66da8bb95f9659"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
