{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Подготовка данных"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Загрузка данных"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "xlsx_file = pd.ExcelFile('input/БОГРАД_PISY.xlsx')\r\n",
    "trees = ['pisy_01a', 'pisy_01b', 'pisy_02a', 'pisy_03a', 'pisy_07a', 'pisy_12b', 'pisy_14a']\r\n",
    "columns = {_:f'D{__}' if __<16 else f'CWT{__-15}' for _, __ in zip(range(2,32), range(1,31))}\r\n",
    "columns[0] = 'Tree'\r\n",
    "columns[1] = 'Year'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Функция нормализации трахеид"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def get_normalized_list(x: list, norm : int):\r\n",
    "    \"\"\"\r\n",
    "    Функция получения нормированного списка\r\n",
    "    :param x: список для нормирования\r\n",
    "    :param norm: норма\r\n",
    "    :return: l_norm - нормированный к e список l\r\n",
    "    \"\"\"\r\n",
    "    l_raw = []  # промежуточный список\r\n",
    "    n = len(x)\r\n",
    "    for i in range(n):\r\n",
    "        for j in range(norm):\r\n",
    "            l_raw += [x[i]]\r\n",
    "    l_norm = []\r\n",
    "    for i in range(norm):\r\n",
    "        l_norm += [1 / n * sum([l_raw[j] for j in range(n * i, n * (i + 1))])]\r\n",
    "    return l_norm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Нормализуем входные данные"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "dataframes = []\r\n",
    "for tree in trees:\r\n",
    "    df = xlsx_file.parse(tree)\r\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\r\n",
    "    df = df.dropna(axis=0)\r\n",
    "\r\n",
    "    norm_traches = dict()\r\n",
    "    for year in set(df['Год']):\r\n",
    "        norm_traches[int(year)] = [tree, int(year)] + get_normalized_list(list(df[df['Год']==year]['Dmean']), 15)+ get_normalized_list(list(df[df['Год']==year]['CWTmean']), 15)\r\n",
    "    \r\n",
    "    dataframes += [pd.DataFrame(norm_traches).transpose().rename(columns=columns).reset_index(drop=True)]\r\n",
    "\r\n",
    "df = pd.concat(dataframes).reset_index(drop=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Сохраняем их в .xlsx файл"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "df.to_excel('output/Bograd_PISY_normalized.xlsx', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Рассчёт средних значений трахеид по годам и по деревьям:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "mean_objects_years = dict()\r\n",
    "\r\n",
    "for year in set(df['Year']):\r\n",
    "    temp_data = df[df['Year']==year]\r\n",
    "    if len(temp_data) > 3:\r\n",
    "        mean_objects_years[year] = temp_data.mean()[1:]\r\n",
    "\r\n",
    "\r\n",
    "mean_objects_trees = dict()\r\n",
    "\r\n",
    "for tree in set(df['Tree']):\r\n",
    "    mean_objects_trees[tree] = df[df['Tree']==tree].mean()[1:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Считаем средние значения трахеид по всем записям"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "global_mean = df.mean()[1:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Строим таблицы объектов для метода A -- кластеризация отклонений средних объектов по году от среднего глобального объекта:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "quotient_deviation_df_A = []\r\n",
    "difference_deviation_df_A = []\r\n",
    "\r\n",
    "_columns = {_:f'D{_}' if _<16 else f'CWT{_-15}' for _ in  range(1,31)}\r\n",
    "_columns[0] = 'Year'\r\n",
    "\r\n",
    "for year, mean_obj in mean_objects_years.items():\r\n",
    "    quotient_deviation_df_A += [[year] + list(mean_obj/global_mean)]\r\n",
    "    difference_deviation_df_A += [[year] + list(mean_obj-global_mean)]\r\n",
    "\r\n",
    "quotient_deviation_df_A = pd.DataFrame(quotient_deviation_df_A).rename(columns=_columns)\r\n",
    "difference_deviation_df_A = pd.DataFrame(difference_deviation_df_A).rename(columns=_columns)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "quotient_deviation_df_A.to_excel('output/quotient_deviation_df_A.xlsx', index=False)\r\n",
    "difference_deviation_df_A.to_excel('output/difference_deviation_df_A.xlsx', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Строим таблицы объектов для метода B -- кластеризация средних отклонений объектов по году от среднего объекта по дереву:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "qd_df_B = []\r\n",
    "dd_df_B = []\r\n",
    "\r\n",
    "quotient_deviation_df_B = dict()\r\n",
    "difference_deviation_df_B = dict()\r\n",
    "\r\n",
    "\r\n",
    "for _, row in df.iterrows():\r\n",
    "    qd_df_B += [[row[0], row[1]] + list(row[2:] / mean_objects_trees[row[0]])]\r\n",
    "    dd_df_B +=  [[row[0], row[1]] + list(row[2:] - mean_objects_trees[row[0]])]\r\n",
    "\r\n",
    "qd_df_B = pd.DataFrame(qd_df_B).rename(columns=columns)\r\n",
    "dd_df_B = pd.DataFrame(dd_df_B).rename(columns=columns)\r\n",
    "\r\n",
    "for year in set(df['Year']):\r\n",
    "    temp_data_q = qd_df_B[qd_df_B['Year']==year]\r\n",
    "    temp_data_d = dd_df_B[dd_df_B['Year']==year]\r\n",
    "    if len(temp_data_q) > 3:\r\n",
    "        quotient_deviation_df_B[year] = temp_data_q.mean()[1:]\r\n",
    "        difference_deviation_df_B[year] = temp_data_d.mean()[1:]\r\n",
    "\r\n",
    "quotient_deviation_df_B = pd.DataFrame(quotient_deviation_df_B).transpose()\r\n",
    "difference_deviation_df_B = pd.DataFrame(difference_deviation_df_B).transpose()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "quotient_deviation_df_B.to_excel('output/quotient_deviation_df_B.xlsx', index=True)\r\n",
    "difference_deviation_df_B.to_excel('output/difference_deviation_df_B.xlsx', index=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Кластеризация"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from sklearn.cluster import KMeans\r\n",
    "from sklearn.metrics import silhouette_score\r\n",
    "\r\n",
    "\r\n",
    "def get_models(data, name='Data'):\r\n",
    "    models = []\r\n",
    "    inertia = []\r\n",
    "    silhouette = []\r\n",
    "    print(name, end=': ')\r\n",
    "    for n_clusters in range(2, 16):\r\n",
    "        print(n_clusters, end=', ')\r\n",
    "        # Описываем модель\r\n",
    "        model = KMeans(n_clusters=n_clusters, max_iter=5000, random_state=0)\r\n",
    "\r\n",
    "        # Проводим моделирование\r\n",
    "        model.fit(data)\r\n",
    "\r\n",
    "        # Предсказание на всем наборе данных\r\n",
    "        all_predictions = model.predict(data)\r\n",
    "\r\n",
    "        # Распихиваем точки по кластерам\r\n",
    "        clusters = [[] for i in range(n_clusters)]\r\n",
    "        for i, num in enumerate(all_predictions):\r\n",
    "            clusters[num] += [data[i]]\r\n",
    "        \r\n",
    "        models += [model]\r\n",
    "        inertia += [model.inertia_]\r\n",
    "        silhouette += [silhouette_score(data, model.labels_, metric='euclidean')]\r\n",
    "    print('done!')\r\n",
    "    return models, inertia, silhouette"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Тут формируем массивы обучабщих выборок для обоих методов:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "quo_data_A  = np.array(quotient_deviation_df_A.drop(['Year'], axis=1))\r\n",
    "diff_data_A = np.array(difference_deviation_df_A.drop(['Year'], axis=1))\r\n",
    "quo_data_B  = np.array(quotient_deviation_df_B)\r\n",
    "diff_data_B = np.array(difference_deviation_df_B)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Обучаем модели для каждого метода:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "models_quo_A, i_1, s_1 = get_models(quo_data_A, 'A quo')\r\n",
    "models_diff_A, i_2, s_2 = get_models(diff_data_A, 'A diff')\r\n",
    "models_quo_B, i_1, s_1 = get_models(quo_data_B, 'B quo')\r\n",
    "models_diff_B, i_2, s_2 = get_models(diff_data_B, 'B diff')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A quo: 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, done!\n",
      "A diff: 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, done!\n",
      "B quo: 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, done!\n",
      "B diff: 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, done!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Функция сохранения графиков кластеров и их средних объектов:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def save_clusters(models, data, amount=15, num=3, data_type='below', ylim=None):\r\n",
    "    all_predictions = models[num-2].predict(data)\r\n",
    "    try:\r\n",
    "        os.mkdir(f'output/{data_type}/')\r\n",
    "    except Exception as e:\r\n",
    "        print(e)\r\n",
    "    try:\r\n",
    "        os.mkdir(f'output/{data_type}/{num}_clust/')\r\n",
    "    except Exception as e:\r\n",
    "        print(e)\r\n",
    "    for j in range(num):\r\n",
    "        fig, ax = plt.subplots( nrows=1, ncols=1)\r\n",
    "        ax.plot(range(1,amount+1), models[num-2].cluster_centers_[j])\r\n",
    "        ax.set_title(f'Mean object (cluster №{j+1})')\r\n",
    "        if ylim:\r\n",
    "            ax.set_ylim(ylim)\r\n",
    "        fig.savefig(f'output/{data_type}/{num}_clust/mean_obj_cluster_{j+1}.png')\r\n",
    "        plt.close(fig)\r\n",
    "        \r\n",
    "        fig, ax = plt.subplots( nrows=1, ncols=1)\r\n",
    "        els = 0\r\n",
    "        for i in range(len(all_predictions)):\r\n",
    "            if all_predictions[i] == j:\r\n",
    "                ax.plot(range(1,amount+1), data[i], label=str(i))\r\n",
    "                els += 1\r\n",
    "        #legend(frameon=False)\r\n",
    "        if ylim:\r\n",
    "            ax.set_ylim(ylim)\r\n",
    "        ax.set_title(f'Cluster №{j+1} ({els} elements)')\r\n",
    "        fig.savefig(f'output/{data_type}/{num}_clust/cluster_{j+1}.png') \r\n",
    "        plt.close(fig)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Сохраняем графики для всех моделей:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "for _ in range(3, 6):\r\n",
    "    save_clusters(models_quo_A, quo_data_A, 30, _, 'A_Quotient', [0.5, 1.5])\r\n",
    "    save_clusters(models_diff_A, diff_data_A, 30, _, 'A_Difference', ylim=[-15, 15])\r\n",
    "    save_clusters(models_quo_B, quo_data_B, 30, _, 'B_Quotient', [0.5, 1.5])\r\n",
    "    save_clusters(models_diff_B, diff_data_B, 30, _, 'B_Difference', ylim=[-15, 15])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[WinError 183] Невозможно создать файл, так как он уже существует: 'output/A_Quotient/'\n",
      "[WinError 183] Невозможно создать файл, так как он уже существует: 'output/A_Difference/'\n",
      "[WinError 183] Невозможно создать файл, так как он уже существует: 'output/B_Quotient/'\n",
      "[WinError 183] Невозможно создать файл, так как он уже существует: 'output/B_Difference/'\n",
      "[WinError 183] Невозможно создать файл, так как он уже существует: 'output/A_Quotient/'\n",
      "[WinError 183] Невозможно создать файл, так как он уже существует: 'output/A_Difference/'\n",
      "[WinError 183] Невозможно создать файл, так как он уже существует: 'output/B_Quotient/'\n",
      "[WinError 183] Невозможно создать файл, так как он уже существует: 'output/B_Difference/'\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Сохраняем таблицы кластеризованных объектов:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "quotient_deviation_df_A['Class 3'] = models_quo_A[1].predict(quo_data_A)\r\n",
    "quotient_deviation_df_A['Class 4'] = models_quo_A[2].predict(quo_data_A)\r\n",
    "quotient_deviation_df_A['Class 5'] = models_quo_A[3].predict(quo_data_A)\r\n",
    "quotient_deviation_df_A.to_excel('output/quotient_deviation_df_A_CLASSIFIED.xlsx', index=False)\r\n",
    "\r\n",
    "difference_deviation_df_A['Class 3'] = models_diff_A[1].predict(diff_data_A)\r\n",
    "difference_deviation_df_A['Class 4'] = models_diff_A[2].predict(diff_data_A)\r\n",
    "difference_deviation_df_A['Class 5'] = models_diff_A[3].predict(diff_data_A)\r\n",
    "difference_deviation_df_A.to_excel('output/difference_deviation_df_A_CLASSIFIED.xlsx', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "quotient_deviation_df_B['Class 3'] = models_quo_B[1].predict(quo_data_B)\r\n",
    "quotient_deviation_df_B['Class 4'] = models_quo_B[2].predict(quo_data_B)\r\n",
    "quotient_deviation_df_B['Class 5'] = models_quo_B[3].predict(quo_data_B)\r\n",
    "quotient_deviation_df_B.to_excel('output/quotient_deviation_df_B_CLASSIFIED.xlsx', index=True)\r\n",
    "\r\n",
    "difference_deviation_df_B['Class 3'] = models_diff_B[1].predict(diff_data_B)\r\n",
    "difference_deviation_df_B['Class 4'] = models_diff_B[2].predict(diff_data_B)\r\n",
    "difference_deviation_df_B['Class 5'] = models_diff_B[3].predict(diff_data_B)\r\n",
    "difference_deviation_df_B.to_excel('output/difference_deviation_df_B_CLASSIFIED.xlsx', index=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Сравнение методов:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "import numpy as np\r\n",
    "from scipy.stats import pearsonr\r\n",
    "\r\n",
    "def dropna_pearsonr(x, y):\r\n",
    "    x, y = np.array(x), np.array(y)\r\n",
    "    nas = np.logical_or(np.isnan(x), np.isnan(y))\r\n",
    "    x, y = x[~nas], y[~nas]\r\n",
    "    r, p = pearsonr(x, y)\r\n",
    "    return r, p\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit"
  },
  "interpreter": {
   "hash": "ea00faadcfb8ab3c64085c6facc6f20135a21130ce7141e34f66da8bb95f9659"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}